{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b70e41b",
   "metadata": {},
   "source": [
    "## 데이터 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae67ad",
   "metadata": {},
   "source": [
    "머신러닝 알고리즘은 문자열 데이터 속성을 입력받지 않기 때문에 모든 데이터를 숫자형으로 표현해야 한다. 이렇게 문자형 같은 사람이 이해할 수 있는 카테고리 속성을 컴퓨터가 이해할 수 있는 숫자값으로 변환하는 것을 인코딩한다고 말한다. 주로 2가지 방법이 있다.\n",
    "- 레이블(Label) 인코딩\n",
    "- 원-핫(One-Hot) 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fc194",
   "metadata": {},
   "source": [
    "### 1. 레이블 인코딩\n",
    "- 상품 분류가 TV, 냉장고, 전자레인지, ... 와 같다면 이를 0, 1, 2, ... 와 같이 숫자로 인코딩하는 방식\n",
    "- 이때 의도하지는 않았지만 1보다 2가 큰 값을 가지게 되는 단점이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4510b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "# fit -> transform의 순서. 이때 fit_transform으로 한번에 처리할 수도 있다\n",
    "encoder.fit(items)\n",
    "# fit을 하면 encoder.classes_ 에 items의 고유한 컬럼만 들어간다\n",
    "labels = encoder.transform(items)\n",
    "print(\"인코딩 변환값:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e6ffa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print(\"인코딩 클래스:\", encoder.classes_)\n",
    "print(\"디코딩 원본값:\", encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1361d",
   "metadata": {},
   "source": [
    "### 2. 원핫인코딩\n",
    "- TV, 냉장고, 전자레인지, ... 처럼 피처 고유 값의 개수만큼 컬럼을 생성해서 해당하는 컬럼에만 1을 표시하고 나머지 컬럼에는 0을 표시하는 인코딩 방식\n",
    "- TV, 냉장고, 전자렌지, ... 같은 컬럼이 생성되고 TV인 경우 TV 컬럼에만 1이, 나머지 컬럼에는 0이 들어간다\n",
    "- OneHotEncoder 클래스를 사용하거나 pandas의 get_dummies를 사용하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdd748",
   "metadata": {},
   "source": [
    "OneHotEncoder를 사용해서 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9cc8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 3)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 2)\t1.0\n",
      "  (7, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# items 리스트를 2차원 ndarray로 변환한다\n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# One-Hot 인코딩을 적용한다 (fit -> transform의 순서. 이때 fit_transform으로 한번에 처리할 수도 있다)\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# OneHotEncoder로 변환한 결과는 희소행렬(Sparse Matrix)이므로 toarray()를 이용해서 밀집행렬(Dense Matrix)로 변환\n",
    "print(oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe7ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "print(oh_labels.toarray())\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad25b74",
   "metadata": {},
   "source": [
    "pandas의 get_dummies 활용해서 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc0c3468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item': ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "# dtype=int로 설정하면 0, 1값을 그렇지 않으면 True, False 값을 반환한다\n",
    "pd.get_dummies(df, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab64db",
   "metadata": {},
   "source": [
    "## 피처 스케일링과 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc531c61",
   "metadata": {},
   "source": [
    "- 목적: 스케일링을 해주면 성능이 향상될 가능성이 있는 모델들이 있음. Tree 같은 모델은 스케일링의 영향을 별로 받지 않고, 선형 계열의 Logistic Regression, SVM 같은 모델은 영향을 받을 가능성이 있는 편이다.\n",
    "- 표준화(Standardization)\n",
    "    - 피처 각각을 평균이 0이고 분산이 1인 표준 정규 분포(standard normal distribution)를 가진 값으로 변환하는 것\n",
    "    - 참고로 정규 분포(normal distribution)는 가우시안 분포라고도 불리며 수집된 데이터들이 평균 근처에 모여있어 종형곡선(bell curve) 형태로 그려진다. 이 중 평균이 0이고 분산이 1인 것이 표준 정규 분포이다\n",
    "    - 사이킷런의 StandardScaler 사용\n",
    "- 정규화(Normalization)\n",
    "    - 데이터 값을 0과 1사이의 범위 값으로 변환 (음수 값이 있으면 -1 ~ 1 값으로 변환)\n",
    "    - 사이킷런의 MinMaxScaler 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f6486",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b858919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일링 전 iris 데이터 피처별 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "스케일링 전 iris 데이터 피처별 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# 먼저 iris 데이터셋을 불러와서 각 피처의 평균값과 분산값을 살펴본다\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "print(\"스케일링 전 iris 데이터 피처별 평균 값\")\n",
    "print(iris_df.mean())\n",
    "print(\"\\n스케일링 전 iris 데이터 피처별 분산 값\")\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5026324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일링 후 iris 데이터 피처별 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "스케일링 후 iris 데이터 피처별 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit -> transform의 단계로 진행 (fit을 하면 스케일링에 필요한 평균, 표준편차 값들을 구하는 듯)\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform을 하면 ndarray를 반환하는데 이를 df로 아래와 같이 변환해줌\n",
    "iris_scaled_df = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print(\"스케일링 후 iris 데이터 피처별 평균 값\")\n",
    "print(iris_scaled_df.mean())\n",
    "print(\"\\n스케일링 후 iris 데이터 피처별 분산 값\")\n",
    "print(iris_scaled_df.var())\n",
    "\n",
    "# 결과가 평균 0, 분산/표준편차가 1에 근사한 값으로 반환되는 것을 확인할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982fe981",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fa533eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케일링 후 iris 데이터 피처별 최소값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "스케일링 후 iris 데이터 피처별 최대값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 동일하게 fit -> transform의 과정을 수행한다\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_scaled_df = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print(\"스케일링 후 iris 데이터 피처별 최소값\")\n",
    "print(iris_scaled_df.min())\n",
    "print(\"\\n스케일링 후 iris 데이터 피처별 최대값\")\n",
    "print(iris_scaled_df.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de1fc7",
   "metadata": {},
   "source": [
    "### 학습/테스트 데이터에 Scaler 적용 시 유의사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "139c29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터를 0 ~ 10, 테스트 데이터에 0 ~ 5를 부여함\n",
    "# scaler의 fit, transform은 2차원 이상 데이터만 가능하므로 reshape 수행\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8b2a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "스케일링 후 데이터 [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler를 적용해보자\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print(\"원본 데이터\", train_array.reshape(-1))\n",
    "print(\"스케일링 후 데이터\", train_scaled.reshape(-1))\n",
    "# 스케일링 후 원본데이터의 값 10이 1로 스케일링 된 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa467643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본데이터 [0 1 2 3 4 5]\n",
      "스케일링 후 데이터 [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 이때 테스트 데이터를 가지고 다시 fit -> transform을 해보면\n",
    "scaler.fit(test_array)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(\"원본데이터\", test_array.reshape(-1))\n",
    "print(\"스케일링 후 데이터\", test_scaled.reshape(-1))\n",
    "# 스케일링 후 원본데이터 값 5가 1로 스케일링 된 것을 확인할 수 있음\n",
    "# 즉, 서로 다른 데이터로 scaler를 만들어서 10과 5가 모두 1로 스케일링 되어버림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e506440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 스케일링 후 [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "테스트 데이터 스케일링 후 [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "# 이를 방지하기 위해서는 모든 데이터로 스케일러를 만들고 스케일링을 적용하든\n",
    "# 학습 데이터로 생성한 스케일러로 테스트 데이터에 transform만 수행해야 한다\n",
    "# 그래야 동일한 기준으로 스케일링을 진행할 수 있다\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print(\"학습 데이터 스케일링 후\", train_scaled.reshape(-1))\n",
    "\n",
    "# 여기서 fit을 호출하지 않고 동일한 scaler를 활용해 transform을 수행한다\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print(\"테스트 데이터 스케일링 후\", test_scaled.reshape(-1))\n",
    "\n",
    "# 여기서는 학습 및 테스트 데이터셋 모두에서 5 -> 0.5로 스케일링 된 것을 확인할 수 있다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
